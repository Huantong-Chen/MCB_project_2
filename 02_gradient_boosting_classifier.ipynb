{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a176f29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier # conda install -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e42eee",
   "metadata": {},
   "source": [
    "# Based on https://stackabuse.com/gradient-boosting-classifiers-in-python-with-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b951d213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    #https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "    #mix two arrays randomly in parallel\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5126adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wildtype_data = np.loadtxt (\"result0_wt.txt\")\n",
    "wildtype_data = wildtype_data [:,1:] # delete first column which is frame number\n",
    "wildtype_label = np.zeros(len(wildtype_data)) #set wildtype labels to 1 \n",
    "\n",
    "mutant_1_data = np.loadtxt (\"result1_D132-H.txt\")\n",
    "mutant_1_data = mutant_1_data [:,1:] # delete first column which is frame number\n",
    "mutant_1_label = np.ones(len(mutant_1_data)) #set mutant labels to 1\n",
    "\n",
    "print('Wildtype Training Data Shape:', wildtype_data.shape)\n",
    "print('Wildtype Label Data Shape:   ', wildtype_label.shape)\n",
    "print('D132-H   Training Data Shape:', mutant_1_data.shape)\n",
    "print('D132-H   Label Data Shape:   ', mutant_1_label.shape)\n",
    "\n",
    "for j in range(1000): # print out examples of random data sets\n",
    "    i = np.random.randint(0, len(wildtype_data)) # pick a random data set\n",
    "    plt.plot(wildtype_data[i], color = \"blue\", alpha = 0.002)\n",
    "    plt.plot(mutant_1_data[i], color = \"red\", alpha = 0.002)\n",
    "plt.savefig(\"input.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2330d19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate combined and shuffled input data file\n",
    "lcp_data = np.vstack((wildtype_data, mutant_1_data))\n",
    "print (\"Combined input_data.shape:\", lcp_data.shape)\n",
    "\n",
    "label_data = np.hstack((wildtype_label, mutant_1_label))\n",
    "print (\"Combined label_data.shape:\", label_data.shape, \"\\n\")\n",
    "\n",
    "# here we shuffle both tensors simultaneously to maintain the labels with each data set\n",
    "lcp_data, label_data = unison_shuffled_copies (lcp_data, label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa61bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  normalize shuffled input data file\n",
    "upper_limit          = int(len (lcp_data)) # get total length of concatenated data\n",
    "upper_training_limit = int(len (lcp_data) * 0.8) # 80% of data used for training\n",
    "print (\"Total number of combined data points:\\t\\t\\t\",upper_limit, \"\\nTotal number of data points selected for training:\\t\", upper_training_limit, \"\\n\")\n",
    "\n",
    "lcp_data = lcp_data/100 # normalizing\n",
    "train_data = lcp_data [0:upper_training_limit,:] # select training data - first 80%\n",
    "test_data  = lcp_data [upper_training_limit:upper_limit,:] # select last 20% for testing\n",
    "\n",
    "train_label = label_data [0:upper_training_limit] # select label data - first 80%\n",
    "test_label  = label_data [upper_training_limit:upper_limit] # select last 20% for testing\n",
    "\n",
    "print (train_data.shape, test_data.shape)\n",
    "print (train_label.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c2b291",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier()\n",
    "xgb_clf.fit(train_data, train_label)\n",
    "score = xgb_clf.score(test_data, test_label)\n",
    "print('\\n\\n Classification Accuracy:\\t', score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
